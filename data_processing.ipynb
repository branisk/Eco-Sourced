{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be97dbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded pdf/arXiv_pdf_1001_001.tar from arxiv to arXiv_pdf_1001_001.tar\n"
     ]
    }
   ],
   "source": [
    "import boto3, configparser\n",
    "\n",
    "configs = configparser.SafeConfigParser()\n",
    "configs.read('config.ini')\n",
    "    \n",
    "# Create an S3 client with your AWS credentials\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    "    region_name='us-east-1'  # same region arxiv bucket is in\n",
    ")\n",
    "\n",
    "# Set the bucket and file key for the desired tar file\n",
    "bucket_name = 'arxiv'\n",
    "file_key = 'pdf/arXiv_pdf_1001_001.tar'\n",
    "\n",
    "# Set the local path where you want to save the downloaded tar file\n",
    "local_path = 'arXiv_pdf_1001_001.tar'\n",
    "\n",
    "# Download the tar file from S3\n",
    "s3.download_file(bucket_name, file_key, local_path, ExtraArgs={'RequestPayer': 'requester'})\n",
    "\n",
    "print(f\"Downloaded {file_key} from {bucket_name} to {local_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d7be6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted arXiv_pdf_1001_001.tar to pdf_files\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "\n",
    "def extract_tar_file(tar_path, output_path):\n",
    "    with tarfile.open(tar_path) as tar:\n",
    "        tar.extractall(output_path)\n",
    "        print(f\"Extracted {tar_path} to {output_path}\")\n",
    "\n",
    "tar_path = 'arXiv_pdf_1001_001.tar'\n",
    "output_path = 'pdf_files'\n",
    "\n",
    "extract_tar_file(tar_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "646ec88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts extracted from PDF files: 920\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "pdf_files_path = 'pdf_files'\n",
    "subfolders = sorted(glob.glob(os.path.join(pdf_files_path, '*')))\n",
    "\n",
    "all_texts = []\n",
    "\n",
    "for subfolder in subfolders:\n",
    "    pdf_files = glob.glob(os.path.join(subfolder, '*.pdf'))\n",
    "    for pdf_file in pdf_files:\n",
    "        with fitz.open(pdf_file) as doc:\n",
    "            text = \"\"\n",
    "            for page in doc:\n",
    "                text += page.get_text()\n",
    "            all_texts.append(text)\n",
    "\n",
    "print(\"Texts extracted from PDF files:\", len(all_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb676fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>pdf_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>arXiv:1001.0487v2  [astro-ph.SR]  5 Jan 2010\\n...</td>\n",
       "      <td>pdf_files/1001/1001.0487.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1 \\nTESTING RELATIVISTIC GRAVITY AND  \\nDETECT...</td>\n",
       "      <td>pdf_files/1001/1001.0213.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>arXiv:1001.0912v1  [hep-th]  6 Jan 2010\\nFIELD...</td>\n",
       "      <td>pdf_files/1001/1001.0912.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>arXiv:1001.0043v2  [astro-ph.EP]  13 Jan 2010\\...</td>\n",
       "      <td>pdf_files/1001/1001.0043.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>arXiv:1001.0371v3  [hep-th]  14 May 2010\\nAcou...</td>\n",
       "      <td>pdf_files/1001/1001.0371.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                           raw_text  \\\n",
       "0      0  arXiv:1001.0487v2  [astro-ph.SR]  5 Jan 2010\\n...   \n",
       "1      1  1 \\nTESTING RELATIVISTIC GRAVITY AND  \\nDETECT...   \n",
       "2      2  arXiv:1001.0912v1  [hep-th]  6 Jan 2010\\nFIELD...   \n",
       "3      3  arXiv:1001.0043v2  [astro-ph.EP]  13 Jan 2010\\...   \n",
       "4      4  arXiv:1001.0371v3  [hep-th]  14 May 2010\\nAcou...   \n",
       "\n",
       "                       pdf_file  \n",
       "0  pdf_files/1001/1001.0487.pdf  \n",
       "1  pdf_files/1001/1001.0213.pdf  \n",
       "2  pdf_files/1001/1001.0912.pdf  \n",
       "3  pdf_files/1001/1001.0043.pdf  \n",
       "4  pdf_files/1001/1001.0371.pdf  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'index': [i for i in range(len(all_texts))], 'raw_text': all_texts, 'pdf_file': pdf_files}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('1001.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d9c0fad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF Folder Size: \n",
      "\t500.25 MB\n",
      "\n",
      "CSV Output Size: \n",
      "\t39.77 MB\n",
      "\n",
      "Total Space Change: \n",
      "\t-460.48 MB\n"
     ]
    }
   ],
   "source": [
    "MB = 1024 * 1024\n",
    "\n",
    "pdfs_size = 0\n",
    "for root, _, files in os.walk('./pdf_files/'):\n",
    "    pdfs_size += sum(os.path.getsize(os.path.join(root, f)) for f in files if not os.path.islink(os.path.join(root, f)))\n",
    "\n",
    "csv_size = os.path.getsize(\"./1001.csv\")\n",
    "\n",
    "print(f\"PDF Folder Size: \\n\\t{pdfs_size / MB:.2f} MB\\n\")\n",
    "print(f\"CSV Output Size: \\n\\t{csv_size / MB:.2f} MB\\n\")\n",
    "print(f\"Total Space Change: \\n\\t{(csv_size - pdfs_size) / MB:.2f} MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
