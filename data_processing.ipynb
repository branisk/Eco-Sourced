{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5641577e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script downloads PDFs from the arXiv AWS S3 bucket, extracts the text\n",
    "from the PDFs, and saves the extracted text as individual text files.\n",
    "WARNING: This script downloads a very large file, 400GB+ as of 05/01/23.\n",
    "\"\"\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import boto3\n",
    "from codecarbon import EmissionsTracker\n",
    "import configparser\n",
    "import tarfile\n",
    "import fitz  # PyMuPDF\n",
    "import glob\n",
    "import logging\n",
    "from multiprocessing import cpu_count, Process\n",
    "import os\n",
    "import re\n",
    "from time import time\n",
    "import shutil\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "tracker = EmissionsTracker(log_level=\"critical\")\n",
    "logging.basicConfig(filename='./log.txt', filemode=\"w\", level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79b4882a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_tar_file(file_key: str) -> None:\n",
    "    \"\"\"\n",
    "    Downloads a tar file containing PDFs from the arXiv AWS S3 bucket.\n",
    "\n",
    "    :param file_key: The key of the tar file in the S3 bucket.\n",
    "    \"\"\"\n",
    "    \n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('config.ini')\n",
    "\n",
    "    aws_access_key_id = config['DEFAULT']['ACCESS_KEY']\n",
    "    aws_secret_access_key = config['DEFAULT']['SECRET_KEY']\n",
    "    \n",
    "    logging.info(f\"Preparing to download ArXiv files from file {file_key}..\")\n",
    "\n",
    "    # Create an S3 client with your AWS credentials\n",
    "    s3 = boto3.client(\n",
    "        's3',\n",
    "        aws_access_key_id=aws_access_key_id,\n",
    "        aws_secret_access_key=aws_secret_access_key,\n",
    "        region_name='us-east-1'  # same region arxiv bucket is in\n",
    "    )\n",
    "\n",
    "    # Set the bucket and file key for the desired tar file\n",
    "    bucket_name = 'arxiv'\n",
    "    local_path = file_key.replace('pdf/', '')\n",
    "\n",
    "    # Download the tar file from S3\n",
    "    s3.download_file(bucket_name, file_key, file_key.replace('pdf/', ''), ExtraArgs={'RequestPayer': 'requester'})\n",
    "\n",
    "    logging.info(f\"Downloaded {file_key} to {local_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b84b3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tar_file(file_key: str) -> None:\n",
    "    \"\"\"\n",
    "    Extracts the PDFs from a downloaded tar file and removes the tar file.\n",
    "\n",
    "    :param file_key: The key of the tar file in the S3 bucket.\n",
    "    \"\"\"\n",
    "    \n",
    "    tar_path = file_key.replace('pdf/', '')\n",
    "    output_path = f'pdf_files/{file_key[-12:-4]}'\n",
    "    \n",
    "    with tarfile.open(tar_path) as tar:\n",
    "        tar.extractall(output_path)\n",
    "        logging.info(f\"Extracted {tar_path} to {output_path}\")\n",
    "        \n",
    "    os.remove(tar_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4fc35c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdfs(file_key: str) -> None:\n",
    "    \"\"\"\n",
    "    Extracts text from the PDFs and saves it to individual text files.\n",
    "\n",
    "    :param file_key: The key of the tar file in the S3 bucket.\n",
    "    \"\"\"\n",
    "    \n",
    "    logging.info(f\"Beginning to extract text from PDF {file_key}\")\n",
    "\n",
    "    pdf_file_num = f\"{file_key[-12:-4]}/{file_key[-12:-8]}\"\n",
    "    pdf_files_path = os.path.join('pdf_files', pdf_file_num)\n",
    "    pdf_files = glob.glob(os.path.join(pdf_files_path, '*.pdf'))\n",
    "\n",
    "    text_files_path = 'text_files'\n",
    "    if not os.path.exists(text_files_path):\n",
    "        os.makedirs(text_files_path)\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        try:\n",
    "            text = extract_text_from_pdf(pdf_file)\n",
    "            save_text_to_file(text, pdf_file, text_files_path)\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Error processing PDF file {pdf_file}: {e}\")\n",
    "            continue\n",
    "\n",
    "    logging.info(\"Texts extracted from PDF files and saved to individual text files.\")\n",
    "    shutil.rmtree(os.path.join('pdf_files', file_key[-12:-4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fd4b31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_file: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts text from a single PDF file.\n",
    "\n",
    "    :param pdf_file: The path of the PDF file.\n",
    "    :return: The extracted text.\n",
    "    \"\"\"\n",
    "    \n",
    "    with fitz.open(pdf_file) as doc:\n",
    "        text = \"\"\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3dc35a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_text_to_file(text: str, pdf_file: str, text_files_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Saves the extracted text to a text file.\n",
    "\n",
    "    :param text: The extracted text.\n",
    "    :param pdf_file: The path of the PDF file.\n",
    "    :param text_files_path: The path of the folder to save the text files.\n",
    "    \"\"\"\n",
    "    \n",
    "    txt_filename = os.path.splitext(os.path.basename(pdf_file))[0] + '.txt'\n",
    "    txt_filepath = os.path.join(text_files_path, txt_filename)\n",
    "    with open(txt_filepath, 'w') as txt_file:\n",
    "        txt_file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "271c3301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tar_from_arxiv() -> tuple[int, list[str]]:\n",
    "    \"\"\"\n",
    "    Retrieves the number of tar files available in the arXiv S3 bucket and\n",
    "    the keys of the tar files.\n",
    "\n",
    "    :return: A tuple containing the number of tar files and a list of their keys.\n",
    "    \"\"\"\n",
    "    \n",
    "    logging.info(\"Attempting to retrieve the number of tar buckets available.\")\n",
    "    \n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('config.ini')\n",
    "\n",
    "    aws_access_key_id = config['DEFAULT']['ACCESS_KEY']\n",
    "    aws_secret_access_key = config['DEFAULT']['SECRET_KEY']\n",
    "    \n",
    "    s3 = boto3.client(\n",
    "        's3',\n",
    "        aws_access_key_id=aws_access_key_id,\n",
    "        aws_secret_access_key=aws_secret_access_key,\n",
    "        region_name='us-east-1'  # same region arxiv bucket is in\n",
    "    )\n",
    "\n",
    "    s3.download_file(\n",
    "            Bucket='arxiv', \n",
    "            Key='pdf/arXiv_pdf_manifest.xml',\n",
    "            Filename='arXiv_pdf_manifest.xml',\n",
    "            ExtraArgs={'RequestPayer':'requester'}\n",
    "    )\n",
    "    manifest = open('arXiv_pdf_manifest.xml', 'r')\n",
    "    soup = BeautifulSoup(manifest, 'xml')\n",
    "    num_tar_files = len(soup.find_all('file'))\n",
    "    filenames = soup.find_all('filename')\n",
    "\n",
    "    # Pattern to match the text between <filename> and </filename>\n",
    "    pattern = r'<filename>(.+)</filename>'\n",
    "\n",
    "    # Use a list comprehension to apply the regex to each string in the list\n",
    "    file_keys = [re.search(pattern, str(s)).group(1) for s in filenames if re.search(pattern, str(s))]\n",
    "    \n",
    "    return num_tar_files, file_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "304f4eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tar_to_txt(file_key: str) -> None:\n",
    "    \"\"\"\n",
    "    Downloads a tar file, extracts the PDFs, and saves the extracted text as\n",
    "    individual text files.\n",
    "\n",
    "    :param file_key: The key of the tar file in the S3 bucket.\n",
    "    \"\"\"\n",
    "    \n",
    "    download_tar_file(file_key)\n",
    "    extract_tar_file(file_key)\n",
    "    extract_text_from_pdfs(file_key)\n",
    "\n",
    "def arxiv_to_txt_parallel() -> None:\n",
    "    \"\"\"\n",
    "    Discovers how many arXiv .tar files are available on S3, then performs\n",
    "    tar_to_txt on each available file to extract pdfs of research papers,\n",
    "    convert the pdfs to text, and saves the text as .txt files.\n",
    "    \"\"\"\n",
    "    \n",
    "    tracker.start()\n",
    "    start = time()\n",
    "\n",
    "    num_tar_files, file_keys = num_tar_from_arxiv()\n",
    "    batch_size = min(16, cpu_count())\n",
    "\n",
    "    print(\"Beginning the process of obtaining PDF's from arXiv's S3 bucket, and converting them to text files.\", flush=True)\n",
    "    print(f\"Utilizing {batch_size} cores to download {num_tar_files} tar files from arXiv's S3 bucket.\\n\", flush=True)\n",
    "\n",
    "    with tqdm(total=num_tar_files, desc=\"Processing data\", unit=\"tar_files\") as progress_bar:\n",
    "        for i in range(0, num_tar_files, batch_size):\n",
    "            processes = [\n",
    "                Process(target=tar_to_txt,\n",
    "                        args=(file_keys[j], )) for j in range(i, min(i + batch_size, num_tar_files))\n",
    "            ]\n",
    "\n",
    "            for process in processes:\n",
    "                process.start()\n",
    "\n",
    "            for idx, process in enumerate(processes):\n",
    "                process.join()\n",
    "                progress_bar.update(1)\n",
    "\n",
    "    print(\"Process complete! All PDF's extracted from S3, converted to text, and stored into './text_files/'.\", flush=True)\n",
    "\n",
    "    tracker.stop()\n",
    "    end = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c080e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning the process of obtaining PDF's from arXiv's S3 bucket, and converting them to text files.\n",
      "Utilizing 16 cores to download 5922 tar files from arXiv's S3 bucket.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d50992fec241d092c34fcc9fe6684c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing data:   0%|          | 0/5922 [00:00<?, ?tar_files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "arxiv_to_txt_parallel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
